{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div>\n",
    "<img src=\"https://i.ibb.co/v3CvVz9/udd-short.png\" width=\"150\"/>\n",
    "    <br>\n",
    "    <strong>Universidad del Desarrollo</strong><br>\n",
    "    <em>Magíster en Data Science</em><br>\n",
    "    <em>Profesor: Tomás Fontecilla </em><br>\n",
    "\n",
    "</div>\n",
    "\n",
    "# Machine Learning Avanzado\n",
    "*02 de Diciembre de 2024*\n",
    "\n",
    "#### Integrantes: \n",
    "` Gabriel Álvarez - Rosario Valderrama `"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Objetivo\n",
    "\n",
    "El objetivo de este informe es ajustar **redes neuronales convolucionales** para realizar un análisis de ciencia de datos utilizando la base extraída de Kaggle ` chihuahuas vs muffins `. Luego, compararemos los resultados con un **modelo de perceptrón multicapa**.\n",
    "\n",
    "A ambos modelos se aplicará 3 estructuras diferentes: \n",
    "- Regularización L1\n",
    "- Dropout\n",
    "- Dacay"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install setuptools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install -r requirements.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Introducción"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A través del dataset ` chihuahuas vs muffins ` que son imágenes, se busca entrenar un modelo de clasificación de redes neuronales (perceptrón multicapa y convolucionales) para lograr clasificar correctamente cada imagen. Para esto, los pasos a seguir son:\n",
    "\n",
    "1. Cargar las imágenes\n",
    "2. Preprocesar las imágenes\n",
    "3. Crear el modelo\n",
    "4. Entrenar el modelo\n",
    "5. Evaluar el modelo\n",
    "6. Guardar el modelo\n",
    "7. Hacer predicciones"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Metodología"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para comenzar, se carga las imágenes desde las carpetas data/train y data/test, donde se infieren las etiquetas de ellas basándose en los nombres de las subcarpetas. Todas las imágenes se redimensionan a 128 x 128 para asegurar que todas tengan el mismo tamaño, para luego agruparlas en lotes de 32 imágenes, lo que permite poder procesarlas de forma más eficiente. Todas las imágenes son \"barajadas\" del conjunto de entrenamiento, para así evitar patrones en el orden de los datos que finalmente afecte este entrenamiento.\n",
    "\n",
    "Se normalizan los valores de cada pixel de las imágenes, dividiéndolos por 255, para que así estén dentro del rango de 0 a 1. Si no se aplicara esta normalización, los valores podrían estar en el rango del 0 a 255, dificultando así la convergencia del modelo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 4733 files belonging to 2 classes.\n",
      "Found 1184 files belonging to 2 classes.\n",
      "Clases detectadas: ['chihuahua', 'muffin']\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.utils import image_dataset_from_directory\n",
    "from tensorflow.keras import layers, models, Sequential\n",
    "\n",
    "# Directorios\n",
    "train_dir = \"data/train\"\n",
    "test_dir = \"data/test\"\n",
    "\n",
    "# 1. Cargar las imágenes\n",
    "train_dataset = image_dataset_from_directory(\n",
    "    train_dir,\n",
    "    labels='inferred',\n",
    "    label_mode='int',\n",
    "    image_size=(128, 128),  # Tamaño fijo\n",
    "    batch_size=32,\n",
    "    shuffle=True\n",
    ")\n",
    "\n",
    "test_dataset = image_dataset_from_directory(\n",
    "    test_dir,\n",
    "    labels='inferred',\n",
    "    label_mode='int',\n",
    "    image_size=(128, 128),\n",
    "    batch_size=32,\n",
    "    shuffle=False\n",
    ")\n",
    "\n",
    "# Inspección de los datos\n",
    "class_names = train_dataset.class_names\n",
    "print(f\"Clases detectadas: {class_names}\")\n",
    "\n",
    "# Normalización (valores entre 0 y 1)\n",
    "normalization_layer = layers.Rescaling(1./255)\n",
    "train_dataset = train_dataset.map(lambda x, y: (normalization_layer(x), y))\n",
    "test_dataset = test_dataset.map(lambda x, y: (normalization_layer(x), y))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dado a que el perceptrón multicapa no puede procesar las imágenes en 2D, requiere que las imágenes se transformen en vectores 1D. Para esto, se busca aplanar las imágenes, convirtiendo cada imagen de 128 x 128 x 3 (RGB) en un vector 1D de tamaño 49152."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Aplanar las imágenes para el MLP\n",
    "# Convierte imágenes 2D en vectores 1D\n",
    "def flatten_images(x, y):\n",
    "    flat_dim = 128 * 128 * 3  # Tamaño fijo de las imágenes aplanadas\n",
    "    x = tf.reshape(x, [tf.shape(x)[0], flat_dim])  # Garantiza que sea un tensor válido\n",
    "    return x, y\n",
    "\n",
    "train_dataset_flat = train_dataset.map(flatten_images)\n",
    "test_dataset_flat = test_dataset.map(flatten_images)\r\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "El modelo del perceptrón multicapa se construye utilizando la API **Sequiential** de TensorFlow/Keras, lo que permite definir una arquitectura de red neuronal de manera secuencial, que va atravesando capa por capa.\n",
    "\n",
    "La primera capa, llamada Input, especifica la forma de las entradas del modelo, que corresponde a vectores del tamaño 128 x 128 x 3 = 49152, resultado de aplanar las imágenes RGB de entrada que previamente se redimencionaron a 128 x 128 pixeles. \n",
    "\n",
    "Posteriormente, se definen 3 capas ocultas densas llamadas **dense**, que están completamente conectadas. Esto significa que cada neurona de una capa está conectada a todas las neuronas de la siguiente capa. La primera capa oculta contiene 256 neuronas, la segunda 128 neuronas y la tercera 64 neuronas.\n",
    "\n",
    "Todas las capas ocultas usan la función de activación ReLU,que se selecciona por su capacidad para introducir no linealidad en la red, permitiendo que el modelo aprenda relaciones complejas entre los datos de entrada y los de salida. Esta función activa únicamente valores positivos (los deja sin cambios) y transforma los valores negativos a cero. Esto mejora la eficiencia computacional en comparación con otras funciones de activación y ayuda a evitar problemas como el desvanecimiento del gradiente, que puede ralentizar el aprendizaje en redes profundas. Al activar solo ciertas neuronas según las entradas, ReLU también ayuda a que la red se enfoque en características relevantes, optimizando su capacidad de generalización.\n",
    "\n",
    "Finalmente, la capa de salida también es densa y tiene tantas neuronas como clases en el problema, lo cual se especifica como len(class_names). En este caso, las clases corresponden a las categorías de las imágenes (chihuahuas y muffins). Esta capa utiliza la función de activación softmax, que convierte las salidas en probabilidades normalizadas, asignando una probabilidad a cada clase. Se utiliza esta activación ya que permite interpretar la salida del modelo como la probabilidad de que una imagen pertenezca a cada clase.\n",
    "\n",
    "En conjunto, estas capas y funciones de activación permiten que el modelo procese los datos de entrada, aprenda patrones significativos en las imágenes y genere predicciones probabilísticas sobre las clases a las que pertenece cada imagen. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Crear el modelo MLP\n",
    "mlp_model = Sequential([\n",
    "    layers.Input(shape=(128*128*3,)),  # Imágenes aplanadas (128x128x3)\n",
    "    layers.Dense(256, activation='relu'),\n",
    "    layers.Dense(128, activation='relu'),\n",
    "    layers.Dense(64, activation='relu'),\n",
    "    layers.Dense(len(class_names), activation='softmax')  # Número de clases\n",
    "])\n",
    "\n",
    "# Compilar el modelo\n",
    "mlp_model.compile(\n",
    "    optimizer='adam',\n",
    "    loss='sparse_categorical_crossentropy',\n",
    "    metrics=['accuracy']\n",
    ")\n",
    "\n",
    "# Resumen del modelo\n",
    "mlp_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Entrenar el modelo\n",
    "mlp_model.fit(train_dataset_flat, epochs=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluar el modelo\n",
    "loss, accuracy = mlp_model.evaluate(test_dataset_flat)\n",
    "print(\"Pérdida del MLP:\", loss)\n",
    "print(\"Exactitud del MLP:\", accuracy)\n",
    "\n",
    "rint(f\"Pérdida del MLP: {loss}\")\n",
    "print(f\"Exactitud del MLP: {accuracy}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para la comparación de ambos modelos:\n",
    "- Desempeño: ¿Qué modelo tiene mayor precisión?\n",
    "- Capacidad de generalización: ¿Cuál tiene menor pérdida en el conjunto de prueba?\n",
    "- Velocidad de entrenamiento: ¿Cuál fue más rápido?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.utils import image_dataset_from_directory\n",
    "from tensorflow.keras import layers, models, regularizers\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dir = \"data/train\"\n",
    "test_dir = \"data/test\"\n",
    "\n",
    "# Carga los datasets\n",
    "train_dataset = image_dataset_from_directory(\n",
    "    train_dir,\n",
    "    labels='inferred',         # Las etiquetas se infieren del nombre de la carpeta\n",
    "    label_mode='int',          # Etiquetas como enteros\n",
    "    image_size=(128, 128),     # Redimensiona las imágenes a 128x128\n",
    "    batch_size=32,             # Tamaño del lote\n",
    "    shuffle=True               # Mezcla los datos\n",
    ")\n",
    "\n",
    "test_dataset = image_dataset_from_directory(\n",
    "    test_dir,\n",
    "    labels='inferred',\n",
    "    label_mode='int',\n",
    "    image_size=(128, 128),\n",
    "    batch_size=32,\n",
    "    shuffle=False\n",
    ")\n",
    "# Inspección de los datos\n",
    "class_names = train_dataset.class_names\n",
    "print(f\"Clases detectadas: {class_names}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Opcional: Normalización de imágenes (valores entre 0 y 1)\n",
    "normalization_layer = tf.keras.layers.Rescaling(1./255)\n",
    "\n",
    "train_dataset = train_dataset.map(lambda x, y: (normalization_layer(x), y))\n",
    "test_dataset = test_dataset.map(lambda x, y: (normalization_layer(x), y))\n",
    "\n",
    "\n",
    "\n",
    "# Opcional: Configuración para prefetching (mejora el rendimiento durante el entrenamiento)\n",
    "# AUTOTUNE = tf.data.AUTOTUNE\n",
    "# train_dataset = train_dataset.prefetch(buffer_size=AUTOTUNE)\n",
    "# test_dataset = test_dataset.prefetch(buffer_size=AUTOTUNE)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Definir el modelo de la CNN\n",
    "model = models.Sequential([\n",
    "    # Primera capa convolucional\n",
    "    layers.Conv2D(32, (3, 3), activation='relu', input_shape=(128, 128, 3)),\n",
    "    layers.MaxPooling2D((2, 2)),\n",
    "\n",
    "    # Segunda capa convolucional\n",
    "    layers.Conv2D(64, (3, 3), activation='relu'),\n",
    "    layers.MaxPooling2D((2, 2)),\n",
    "\n",
    "    # Tercera capa convolucional\n",
    "    layers.Conv2D(128, (3, 3), activation='relu'),\n",
    "    layers.MaxPooling2D((2, 2)),\n",
    "\n",
    "    # Aplanar y agregar capas densas\n",
    "    layers.Flatten(),\n",
    "    layers.Dense(128, activation='relu'),\n",
    "    layers.Dense(64, activation='relu'),\n",
    "\n",
    "    # Capa de salida (número de clases)\n",
    "    layers.Dense(len(class_names), activation='softmax')  # len(class_names) = número de clases\n",
    "])\n",
    "\n",
    "# Compilar el modelo\n",
    "model.compile(\n",
    "    optimizer='adam',\n",
    "    loss='sparse_categorical_crossentropy',\n",
    "    metrics=['accuracy']\n",
    ")\n",
    "\n",
    "# Resumen del modelo\n",
    "model.summary()\n",
    "\n",
    "# Entrenar el modelo\n",
    "model.fit(train_dataset, epochs=10)\n",
    "\n",
    "# Evaluar el modelo\n",
    "loss, accuracy = model.evaluate(test_dataset)\n",
    "print(f\"Pérdida: {loss}\")\n",
    "print(f\"Exactitud: {accuracy}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
